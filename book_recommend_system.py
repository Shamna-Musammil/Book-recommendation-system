# -*- coding: utf-8 -*-
"""Book_recommend_system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OgTlO5A5QcIhjf1mBMzk9HF6mX9_hb_G
"""

import numpy as np
import pandas as pd

books = pd.read_csv('/content/Books.csv')
users = pd.read_csv('/content/Users.csv')
ratings = pd.read_csv('/content/Ratings.csv')

books.head()

users.head()

ratings.head()

print(books.isnull().sum())
print(ratings.isnull().sum() )
print(users.isnull().sum())

ratings_with_name = ratings.merge(books,on='ISBN') 
ratings_with_name

"""# **Popularity Based Recommender System**
We will display the top 50 books with highest average rating (provided 250 people rated the book )
"""

#find number of ratings each book got
num_rating_df = ratings_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index()
num_rating_df.rename(columns={'Book-Rating':'num_ratings'},inplace=True)

num_rating_df

#find average rating
avg_rating_df = ratings_with_name.groupby('Book-Title').mean()['Book-Rating'].reset_index()
avg_rating_df.rename(columns={'Book-Rating':'avg_rating'},inplace=True)
avg_rating_df

popular_df = num_rating_df.merge(avg_rating_df,on='Book-Title')

popular_df = popular_df[popular_df['num_ratings']>=250].sort_values('avg_rating',ascending=False).head(50) 

popular_df = popular_df.merge(books,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating']]

popular_df

popular_df.shape



"""#Collaberative filtering based recommended system
We will show books with 50 ratings from the users who has rated more than 200 books(experienced users).
To recommend related books of a selected book, we can use this set of books
"""

x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 200
experienced_users=x[x].index

filtered_rating=ratings_with_name[ratings_with_name['User-ID'].isin(experienced_users)]

y=filtered_rating.groupby('Book-Title').count()['Book-Rating']>=50
famous_books = y[y].index
famous_books

final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]

#create pivot table 
pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')
pt.fillna(0,inplace=True)
pt

# fetch similarity score each book with others

from sklearn.metrics.pairwise import cosine_similarity
similarity_scores = cosine_similarity(pt)
similarity_scores

pt.index

# find the books which has greater similarity score with the given book

def recommend(book_name):
    # index fetch
    index = np.where(pt.index==book_name)[0][0]
    print(book_name)
    print(index)
    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]
    
    data = []
    for i in similar_items:
        item = []
        temp_df = books[books['Book-Title'] == pt.index[i[0]]]
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))
        
        data.append(item)
    
    return data

recommend('A Map of the World')

import pickle
pickle.dump(popular_df,open('popular.pkl','wb'))
pickle.dump(pt,open('pt.pkl','wb'))
pickle.dump(similarity_scores,open('similarity_scores.pkl','wb'))
pickle.dump(books,open('books.pkl','wb'))